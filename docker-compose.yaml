version: '3.10'

services:
  # БД всего проекта под логи, артефакты и тд
  mlops_db:
    image: postgres:14
    restart: always
    container_name: mlops_db
    volumes: 
      - ./storage_db:/var/lib/postgresql/data
      - ./params/db_init.sh:/docker-entrypoint-initdb.d/db_init.sh
    environment: 
      - MLFLOW_DB=${MLFLOW_DB}
      - DAGSTER_DB=${DAGSTER_DB}
      - POSTGRES_USER=${MLOPS_DB_USER}
      - POSTGRES_PASSWORD=${MLOPS_DB_PASSWORD}
    expose:
      - ${MLOPS_DB_PORT}
    command: -p ${MLOPS_DB_PORT}
    networks:
      - mlflow_net
  # data lake для хранения мелких артифактов и моделей
  s3:
    image: minio/minio
    restart: always
    container_name: mlflow_s3
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./storage_minio:/data
    environment:
      MINIO_ACCESS_KEY: ${AWS_ACCESS_KEY_ID}
      MINIO_SECRET_KEY: ${AWS_SECRET_ACCESS_KEY}
    command: server --address ":9000" --console-address ":9001" /data/
    networks:
      - mlflow_net
  # Сервер трекинга и организации ML работ
  mlflow_server:
    image: mlflow_server
    restart: always
    build:
      context: .
      dockerfile: ./dockerfile_mlflow
    container_name: mlflow_server
    environment:
      - BACKEND=postgresql://${MLOPS_DB_USER}:${MLOPS_DB_PASSWORD}@mlops_db:${MLOPS_DB_PORT}/${MLFLOW_DB}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - ARTIFACTS=s3://${AWS_BUCKET_NAME}
      - MLFLOW_S3_ENDPOINT_URL=http://s3:9000
    ports:
      - ${MLFLOW_PORT}:${MLFLOW_PORT}
    command: 
      - sh
      - -c
      - mlflow server 
        --host 0.0.0.0
        --port ${MLFLOW_PORT}
        --serve-artifacts
        --backend-store-uri $${BACKEND} 
        --artifacts-destination $${ARTIFACTS}
    depends_on: 
      - mlops_db
      - s3
    networks:
      - mlflow_net

  # Докер служба для оркестратора, чтобы он мог поднимать отдельные докеры под отдельные раны
  dagit:
    build:
      context: .
      dockerfile: ./dockerfile_dagster

    entrypoint:
      - dagit
      - -h
      - "0.0.0.0"
      - -p
      - ${DAGSTER_PORT}
      - -w
      - workspace.yaml
    container_name: dagit
    environment:
        DB_USER: ${MLOPS_DB_USER}
        DB_PASSWORD: ${MLOPS_DB_PASSWORD}
        MLOPS_DB_PORT: ${MLOPS_DB_PORT}
        DAGSTER_DB: ${DAGSTER_DB}
    volumes:
      - ./params/workspace.yaml:/opt/dagster/dagster_home/workspace.yaml
      - ./params/dagster.yaml:/opt/dagster/dagster_home/dagster.yaml
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - ${DAGSTER_PORT}:${DAGSTER_PORT}
    networks:
      - mlflow_net
    depends_on:
      - mlops_db

  # # This service runs the dagster-daemon process, which is responsible for taking runs
  # # off of the queue and launching them, as well as creating runs from schedules or sensors.
  dagster_daemons:
    build:
      context: .
      dockerfile: ./dockerfile_dagster
    entrypoint:
      - dagster-daemon
      - run
    container_name: dagster_daemons
    environment:
        DB_USER: ${MLOPS_DB_USER}
        DB_PASSWORD: ${MLOPS_DB_PASSWORD}
        MLOPS_DB_PORT: ${MLOPS_DB_PORT}
        DAGSTER_DB: ${DAGSTER_DB}
    volumes:
      - ./params/workspace.yaml:/opt/dagster/dagster_home/workspace.yaml
      - ./params/dagster.yaml:/opt/dagster/dagster_home/dagster.yaml
      - /var/run/docker.sock:/var/run/docker.sock
    restart: on-failure
    networks:
      - mlflow_net
    depends_on:
      - mlops_db

networks:
  mlflow_net:
    driver: bridge

